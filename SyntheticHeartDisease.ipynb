{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4v9bLALaSv0",
        "outputId": "fae13275-5b72-49d2-c309-413640fdeadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of generated data:\n",
            "   age  sex    trestbps        chol  fbs  restecg     thalach  exang  \\\n",
            "0   67    1  161.422676  184.774113    0        0  152.399155      1   \n",
            "1   57    0  126.550049  326.584251    1        1  103.227918      0   \n",
            "2   43    1  146.891063  202.569424    0        1  168.658125      1   \n",
            "3   71    1  134.556393  236.731622    1        0  110.976761      0   \n",
            "4   36    1  138.488759  314.857487    1        0   93.606141      1   \n",
            "\n",
            "    oldpeak  slope  ca  thal  target  \n",
            "0  1.250268      2   2     3       1  \n",
            "1  1.430917      1   0     1       1  \n",
            "2  1.257099      0   1     1       0  \n",
            "3  0.000000      2   2     2       1  \n",
            "4  0.000000      0   0     1       0  \n",
            "Accuracy:        0.624\n",
            "ROC AUC:         0.67395725\n",
            "Precision:       0.6241241241241241\n",
            "Recall:          0.6235\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62      2000\n",
            "           1       0.62      0.62      0.62      2000\n",
            "\n",
            "    accuracy                           0.62      4000\n",
            "   macro avg       0.62      0.62      0.62      4000\n",
            "weighted avg       0.62      0.62      0.62      4000\n",
            "\n",
            "\n",
            "Model and scaler saved to disk.\n"
          ]
        }
      ],
      "source": [
        "# heart_disease_synthetic.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, recall_score, classification_report\n",
        ")\n",
        "import joblib\n",
        "\n",
        "def generate_synthetic_heart_data(n_samples=20000, random_state=42):\n",
        "    \"\"\"\n",
        "    Generates synthetic heart disease data with biologically inspired distributions.\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    age = np.random.randint(29, 78, size=n_samples)\n",
        "    sex = np.random.binomial(1, 0.54, size=n_samples)\n",
        "    trestbps = np.random.normal(130, 20, size=n_samples).clip(80, 200)\n",
        "    chol = np.random.normal(246, 50, size=n_samples).clip(100, 400)\n",
        "    fbs = np.random.binomial(1, 0.15, size=n_samples)\n",
        "    restecg = np.random.choice([0, 1, 2], size=n_samples, p=[0.5, 0.42, 0.08])\n",
        "    thalach = np.random.normal(150, 22, size=n_samples).clip(70, 210)\n",
        "    exang = np.random.binomial(1, 0.33, size=n_samples)\n",
        "    oldpeak = np.random.normal(1.0, 1.0, size=n_samples).clip(0.0, 6.0)\n",
        "    slope = np.random.choice([0, 1, 2], size=n_samples)\n",
        "    ca = np.random.poisson(1.0, size=n_samples).clip(0, 3)\n",
        "    thal = np.random.choice([1, 2, 3], size=n_samples, p=[0.54, 0.28, 0.18])\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'sex': sex,\n",
        "        'trestbps': trestbps,\n",
        "        'chol': chol,\n",
        "        'fbs': fbs,\n",
        "        'restecg': restecg,\n",
        "        'thalach': thalach,\n",
        "        'exang': exang,\n",
        "        'oldpeak': oldpeak,\n",
        "        'slope': slope,\n",
        "        'ca': ca,\n",
        "        'thal': thal\n",
        "    })\n",
        "\n",
        "    # Simple risk function to generate labels\n",
        "    risk_score = (\n",
        "        0.02 * age +\n",
        "        0.01 * trestbps +\n",
        "        0.005 * chol +\n",
        "        0.5 * exang +\n",
        "        0.3 * ca -\n",
        "        0.01 * thalach +\n",
        "        np.random.normal(0, 1.5, size=n_samples)\n",
        "    )\n",
        "\n",
        "    # Convert risk to probability and then binary label\n",
        "    prob = 1 / (1 + np.exp(- (risk_score - np.median(risk_score)) / 5))\n",
        "    df['target'] = (prob > 0.5).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "def train_and_evaluate(df):\n",
        "    \"\"\"\n",
        "    Trains a logistic regression model and evaluates performance.\n",
        "    Saves the model and scaler to disk.\n",
        "    \"\"\"\n",
        "    X = df.drop(columns='target')\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=1, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    num_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
        "\n",
        "    # One-hot encode categorical features\n",
        "    X_train = pd.get_dummies(X_train, columns=['sex', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'], drop_first=True)\n",
        "    X_test = pd.get_dummies(X_test, columns=['sex', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'], drop_first=True)\n",
        "\n",
        "    # Ensure same columns\n",
        "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "    # Train logistic regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"Accuracy:       \", accuracy_score(y_test, y_pred))\n",
        "    print(\"ROC AUC:        \", roc_auc_score(y_test, y_proba))\n",
        "    print(\"Precision:      \", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:         \", recall_score(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Save model and scaler\n",
        "    joblib.dump(model, 'heart_disease_model.pkl')\n",
        "    joblib.dump(scaler, 'scaler.pkl')\n",
        "    print(\"\\nModel and scaler saved to disk.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = generate_synthetic_heart_data(n_samples=20000)\n",
        "    print(\"Sample of generated data:\")\n",
        "    print(df.head())\n",
        "\n",
        "    train_and_evaluate(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWPqeA22bKjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}